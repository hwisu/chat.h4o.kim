import { Hono } from 'hono';
import { Env, ChatCompletionResponse, ChatMessage } from '../types';
import { getRoleSystemPrompt } from '../roles';
import {
  estimateTokenCount,
  buildMessagesWithSummary,
  processSummarization
} from '../services/summarization';
import { contextManager } from '../services/context-manager';
import { checkAuthenticationOrUserKey } from './auth';
import { getApiKey, getSelectedModel } from './models';
import { getUserRole, getSessionId } from './roles';

const chat = new Hono<{ Bindings: Env }>();

// ì‚¬ìš©ì ID íšë“ í—¬í¼ í•¨ìˆ˜
function getUserId(c: any): string {
  const sessionToken = c.req.header('X-Session-Token');
  const userApiKey = c.req.header('X-User-API-Key');
  return contextManager.getUserId(sessionToken, userApiKey);
}

// GET /api/help - ë„ì›€ë§ ë°˜í™˜
chat.get('/help', async (c) => {
  return c.json({
    success: true,
    response: `ğŸ“– Chatty Commands:\n\nğŸ” Authentication:\n/login <password>          - Authenticate with server\n\nğŸ”‘ API Key Management:\n/set-api-key <key>         - Set your personal OpenRouter API key\n/remove-api-key            - Remove personal API key (use server key)\n/api-key-status            - Check current API key status\n\nğŸ­ Role Management:\n/roles                     - List available AI roles\n/set-role <role-id>        - Set AI personality/role\n\nğŸ¤– Model Commands:\n/models                    - List available AI models\n/set-model <id>            - Set specific model\n/set-model auto            - Use auto-selection\n\nğŸ’¬ Chat Commands:\n/clear                     - Clear conversation history\n/token-info [on|off]       - Toggle token usage display\n/help                      - Show this help\n\nğŸ’¡ Features:\nâ€¢ Personal API key support (stored locally & encrypted)\nâ€¢ Role-based AI personalities for specialized tasks\nâ€¢ Conversation context maintained across messages\nâ€¢ Automatic summarization at 24k tokens for efficiency\nâ€¢ Smart token management with detailed usage tracking\nâ€¢ Optimized parameters for better responses\n\nğŸŒ Get your API key: https://openrouter.ai/settings/keys`
  });
});

// ì»¨í…ìŠ¤íŠ¸ ì²˜ë¦¬ ë° ìš”ì•½ í•¨ìˆ˜
interface ContextProcessingResult {
  finalMessages: ChatMessage[];
  currentSummary: string | null;
  summaryData: any;
  actualTokenCount: number;
}

async function processContextAndSummary(
  chatMessages: ChatMessage[],
  currentSummary: string | null,
  newMessage: string,
  systemPrompt: string,
  apiKey: string
): Promise<ContextProcessingResult> {
  // í˜„ì¬ ìƒíƒœë¡œ ì„ì‹œ ë©”ì‹œì§€ êµ¬ì„±í•´ì„œ ì‹¤ì œ í† í° ìˆ˜ í™•ì¸
  const preliminaryMessages = buildMessagesWithSummary(
    chatMessages,
    currentSummary,
    newMessage,
    systemPrompt
  );

  const actualTokenCount = estimateTokenCount(preliminaryMessages.map(m => ({
    role: m.role,
    content: m.content,
    timestamp: Date.now()
  })));

  const needsSummary = actualTokenCount > 24000 && !currentSummary;

  let summaryData: any = null;
  let finalMessages = chatMessages;
  let finalSummary = currentSummary;

  if (needsSummary) {
    try {
      summaryData = await processSummarization(chatMessages, apiKey);
      finalMessages = summaryData.remainingMessages;
      finalSummary = summaryData.summary;
    } catch (error) {
      console.warn('Auto-summary failed, proceeding without summary:', error);
    }
  }

  return {
    finalMessages,
    currentSummary: finalSummary,
    summaryData,
    actualTokenCount
  };
}

// API ìš”ì²­ ì¤€ë¹„ í•¨ìˆ˜
function prepareChatRequest(
  messages: any[],
  selectedModel: string,
  temperature: number = 0.7,
  max_tokens: number = 1500,
  top_p: number = 0.9,
  frequency_penalty: number = 0.1,
  presence_penalty: number = 0.1
) {
  return {
    model: selectedModel,
    messages: messages,
    max_tokens: max_tokens,
    temperature: temperature,
    top_p: top_p,
    frequency_penalty: frequency_penalty,
    presence_penalty: presence_penalty,
    stream: false
  };
}

// íƒ€ì„ì•„ì›ƒê³¼ í•¨ê»˜ OpenRouter APIë¥¼ í˜¸ì¶œí•˜ëŠ” í•¨ìˆ˜
async function callOpenRouterAPI(apiKey: string, body: any, timeoutMs: number = 15000): Promise<Response> {
  // íƒ€ì„ì•„ì›ƒ ì„¤ì •ìœ¼ë¡œ ì‘ë‹µ ì†ë„ ê°œì„ 
  const controller = new AbortController();
  const timeoutId = setTimeout(() => controller.abort(), timeoutMs);

  try {
    const response = await fetch('https://openrouter.ai/api/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${apiKey}`,
        'Content-Type': 'application/json',
        'HTTP-Referer': 'https://chat.h4o.kim',
        'X-Title': 'Chatty',
        'Accept-Encoding': 'gzip, deflate, br'
      },
      body: JSON.stringify(body),
      cf: {
        cacheTtl: 0,
        cacheEverything: false
      },
      signal: controller.signal
    });

    return response;
  } finally {
    clearTimeout(timeoutId);
  }
}

// POST /api/chat - ì„œë²„ ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ì±„íŒ…
chat.post('/chat', async (c) => {
  // Check authentication first
  if (!await checkAuthenticationOrUserKey(c)) {
    return c.json({
      error: 'Authentication required',
      auth_required: true,
      response: `âŒ Authentication required.\n\nUse: /login <password>`
    }, 401);
  }

  try {
    const requestBody: any = await c.req.json();

    // ë‹¨ìˆœí•œ ìš”ì²­ ë°ì´í„° ì²˜ë¦¬
    const {
      message,
      model,
      temperature = 0.7,
      max_tokens = 1500,
      top_p = 0.9,
      frequency_penalty = 0.1,
      presence_penalty = 0.1
    } = requestBody;

    if (!message) {
      return c.json({ error: 'Message is required' }, 400);
    }

    try {
      // ì‚¬ìš©ì ì‹ë³„ ë° ì»¨í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
      const userId = getUserId(c);
      const sessionId = getSessionId(c);
      const currentRole = getUserRole(sessionId);

      // ì„œë²„ì—ì„œ ì»¨í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°/ìƒì„±
      const context = await contextManager.getOrCreateContext(userId);

      // API í‚¤ ë° ëª¨ë¸ ì„¤ì •
      const apiKey = getApiKey(c);
      const selectedModel = await getSelectedModel(c, model, true);
      const systemPrompt = getRoleSystemPrompt(currentRole);

      // ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ì»¨í…ìŠ¤íŠ¸ì— ì¶”ê°€
      await contextManager.addMessage(userId, 'user', message);

      // í˜„ì¬ ì»¨í…ìŠ¤íŠ¸ ìƒíƒœ ê°€ì ¸ì˜¤ê¸° (ë°©ê¸ˆ ì¶”ê°€í•œ ë©”ì‹œì§€ í¬í•¨)
      const updatedContext = await contextManager.getOrCreateContext(userId);

      // ì»¨í…ìŠ¤íŠ¸ ì²˜ë¦¬ ë° ìš”ì•½
      const contextResult = await processContextAndSummary(
        updatedContext.conversationHistory,
        updatedContext.summary,
        message,
        systemPrompt,
        apiKey
      );

      // ìµœì¢… ë©”ì‹œì§€ êµ¬ì„±
      const messages = buildMessagesWithSummary(
        contextResult.finalMessages.filter(m => m.role !== 'user' || m.content !== message), // ì¤‘ë³µ ë°©ì§€
        contextResult.currentSummary,
        message,
        systemPrompt
      );

      // API ìš”ì²­ ì¤€ë¹„
      const chatRequestBody = prepareChatRequest(
        messages,
        selectedModel,
        temperature,
        max_tokens,
        top_p,
        frequency_penalty,
        presence_penalty
      );

      const chatResponse = await callOpenRouterAPI(apiKey, chatRequestBody);

      if (!chatResponse.ok) {
        const errorText = await chatResponse.text();
        console.error('OpenRouter API error:', {
          status: chatResponse.status,
          statusText: chatResponse.statusText,
          model: selectedModel,
          messageCount: messages.length
        });

        if (chatResponse.status === 401) {
          return c.json({
            error: 'Invalid API key. Please check your OpenRouter API key.',
            details: errorText,
            auth_required: true
          }, 401);
        }

        return c.json({
          error: `Chat API error: ${chatResponse.status}`,
          details: errorText
        }, 500);
      }

      const chatData: ChatCompletionResponse = await chatResponse.json();

      if (!chatData.choices?.[0]?.message) {
        return c.json({ error: 'Invalid response structure' }, 500);
      }

      const assistantResponse = chatData.choices[0].message.content || '';

      // ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µì„ ì»¨í…ìŠ¤íŠ¸ì— ì¶”ê°€
      await contextManager.addMessage(userId, 'assistant', assistantResponse);

      // ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸ (ìš”ì•½, í† í° ì‚¬ìš©ëŸ‰ ë“±)
      await contextManager.updateContext(userId, {
        summary: contextResult.currentSummary,
        conversationHistory: [...contextResult.finalMessages,
          { role: 'user', content: message, timestamp: Date.now() },
          { role: 'assistant', content: assistantResponse, timestamp: Date.now() }
        ],
        tokenUsage: chatData.usage?.total_tokens || 0
      });

      // ì‘ë‹µ ë°ì´í„° êµ¬ì„±
      const responseData = {
        response: assistantResponse,
        model: selectedModel,
        usage: chatData.usage,
        summaryApplied: !!contextResult.summaryData,
        summarizedMessageCount: contextResult.summaryData?.summarizedMessageCount || 0,
        messageCount: updatedContext.conversationHistory.length + 1, // +1 for assistant response
        timestamp: Date.now()
      };

      return c.json(responseData);
    } catch (apiError) {
      console.error('API error:', apiError);
      return c.json({
        error: apiError instanceof Error ? apiError.message : 'API configuration error',
        details: 'Please check your API key configuration'
      }, 500);
    }

  } catch (error) {
    console.error('Chat error:', error);
    return c.json({
      error: 'Failed to process request',
      details: error instanceof Error ? error.message : 'Unknown error'
    }, 500);
  }
});

export default chat;
